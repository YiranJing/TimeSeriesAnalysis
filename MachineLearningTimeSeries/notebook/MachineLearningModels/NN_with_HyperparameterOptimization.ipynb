{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: NN_with_HyperparameterOptimization\n",
    "Author: Rhys Kilian\n",
    "\n",
    "Date: 31-10-2018\n",
    "\n",
    "This is one of many model files which were created in the hyperparameter optimisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhys/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import models from scikit learn module\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df_train = pd.read_csv('../../../0. Data/data_demand_cleaned_ML181026_train.csv', sep='\\t')\n",
    "df_train['period'] = pd.to_datetime(df_train['period'], format='%d/%m/%Y %H:%M')\n",
    "df_train.sort_values(by='period', ascending=True, inplace=True)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>demand</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>price</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_45</th>\n",
       "      <th>lag_46</th>\n",
       "      <th>lag_47</th>\n",
       "      <th>lag_48</th>\n",
       "      <th>lag_49</th>\n",
       "      <th>lag_50</th>\n",
       "      <th>lag_51</th>\n",
       "      <th>lag_334</th>\n",
       "      <th>lag_335</th>\n",
       "      <th>lag_336</th>\n",
       "      <th>lag_337</th>\n",
       "      <th>lag_338</th>\n",
       "      <th>lag_1006</th>\n",
       "      <th>lag_1007</th>\n",
       "      <th>lag_1008</th>\n",
       "      <th>lag_1009</th>\n",
       "      <th>lag_1010</th>\n",
       "      <th>lag_1679</th>\n",
       "      <th>lag_1680</th>\n",
       "      <th>lag_1681</th>\n",
       "      <th>lag_287</th>\n",
       "      <th>lag_288</th>\n",
       "      <th>lag_289</th>\n",
       "      <th>lag_672</th>\n",
       "      <th>lag_671</th>\n",
       "      <th>lag_673</th>\n",
       "      <th>dummy_Balckout</th>\n",
       "      <th>dummy_HeatWaves</th>\n",
       "      <th>dummy_Winter</th>\n",
       "      <th>dummy_Spring</th>\n",
       "      <th>dummy_Summer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-01 00:00:00</td>\n",
       "      <td>1852.77</td>\n",
       "      <td>34.00</td>\n",
       "      <td>46.93</td>\n",
       "      <td>1692.17</td>\n",
       "      <td>1743.35</td>\n",
       "      <td>1850.72</td>\n",
       "      <td>1975.58</td>\n",
       "      <td>2098.78</td>\n",
       "      <td>2209.24</td>\n",
       "      <td>2291.59</td>\n",
       "      <td>1400.48</td>\n",
       "      <td>1465.08</td>\n",
       "      <td>1493.41</td>\n",
       "      <td>1599.68</td>\n",
       "      <td>1429.60</td>\n",
       "      <td>1480.51</td>\n",
       "      <td>1540.91</td>\n",
       "      <td>1205.58</td>\n",
       "      <td>1261.73</td>\n",
       "      <td>1344.08</td>\n",
       "      <td>1175.69</td>\n",
       "      <td>1192.87</td>\n",
       "      <td>1362.40</td>\n",
       "      <td>1388.73</td>\n",
       "      <td>1491.46</td>\n",
       "      <td>1348.77</td>\n",
       "      <td>1355.61</td>\n",
       "      <td>1311.26</td>\n",
       "      <td>1418.21</td>\n",
       "      <td>1244.27</td>\n",
       "      <td>1201.42</td>\n",
       "      <td>1275.00</td>\n",
       "      <td>1100.42</td>\n",
       "      <td>1509.93</td>\n",
       "      <td>1401.17</td>\n",
       "      <td>1335.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-01 00:30:00</td>\n",
       "      <td>1698.09</td>\n",
       "      <td>33.80</td>\n",
       "      <td>70.58</td>\n",
       "      <td>1852.77</td>\n",
       "      <td>1692.17</td>\n",
       "      <td>1743.35</td>\n",
       "      <td>1850.72</td>\n",
       "      <td>1975.58</td>\n",
       "      <td>2098.78</td>\n",
       "      <td>2209.24</td>\n",
       "      <td>1356.33</td>\n",
       "      <td>1400.48</td>\n",
       "      <td>1465.08</td>\n",
       "      <td>1493.41</td>\n",
       "      <td>1599.68</td>\n",
       "      <td>1429.60</td>\n",
       "      <td>1480.51</td>\n",
       "      <td>1133.37</td>\n",
       "      <td>1205.58</td>\n",
       "      <td>1261.73</td>\n",
       "      <td>1344.08</td>\n",
       "      <td>1175.69</td>\n",
       "      <td>1294.11</td>\n",
       "      <td>1362.40</td>\n",
       "      <td>1388.73</td>\n",
       "      <td>1491.46</td>\n",
       "      <td>1348.77</td>\n",
       "      <td>1243.51</td>\n",
       "      <td>1311.26</td>\n",
       "      <td>1418.21</td>\n",
       "      <td>1142.83</td>\n",
       "      <td>1201.42</td>\n",
       "      <td>1275.00</td>\n",
       "      <td>1401.17</td>\n",
       "      <td>1339.87</td>\n",
       "      <td>1509.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-01 01:00:00</td>\n",
       "      <td>1629.32</td>\n",
       "      <td>33.60</td>\n",
       "      <td>119.52</td>\n",
       "      <td>1698.09</td>\n",
       "      <td>1852.77</td>\n",
       "      <td>1692.17</td>\n",
       "      <td>1743.35</td>\n",
       "      <td>1850.72</td>\n",
       "      <td>1975.58</td>\n",
       "      <td>2098.78</td>\n",
       "      <td>1357.86</td>\n",
       "      <td>1356.33</td>\n",
       "      <td>1400.48</td>\n",
       "      <td>1465.08</td>\n",
       "      <td>1493.41</td>\n",
       "      <td>1599.68</td>\n",
       "      <td>1429.60</td>\n",
       "      <td>1090.07</td>\n",
       "      <td>1133.37</td>\n",
       "      <td>1205.58</td>\n",
       "      <td>1261.73</td>\n",
       "      <td>1344.08</td>\n",
       "      <td>1250.07</td>\n",
       "      <td>1294.11</td>\n",
       "      <td>1362.40</td>\n",
       "      <td>1388.73</td>\n",
       "      <td>1491.46</td>\n",
       "      <td>1186.26</td>\n",
       "      <td>1243.51</td>\n",
       "      <td>1311.26</td>\n",
       "      <td>1063.67</td>\n",
       "      <td>1142.83</td>\n",
       "      <td>1201.42</td>\n",
       "      <td>1339.87</td>\n",
       "      <td>1276.82</td>\n",
       "      <td>1401.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-01 01:30:00</td>\n",
       "      <td>1546.72</td>\n",
       "      <td>32.25</td>\n",
       "      <td>105.58</td>\n",
       "      <td>1629.32</td>\n",
       "      <td>1698.09</td>\n",
       "      <td>1852.77</td>\n",
       "      <td>1692.17</td>\n",
       "      <td>1743.35</td>\n",
       "      <td>1850.72</td>\n",
       "      <td>1975.58</td>\n",
       "      <td>1345.53</td>\n",
       "      <td>1357.86</td>\n",
       "      <td>1356.33</td>\n",
       "      <td>1400.48</td>\n",
       "      <td>1465.08</td>\n",
       "      <td>1493.41</td>\n",
       "      <td>1599.68</td>\n",
       "      <td>1070.76</td>\n",
       "      <td>1090.07</td>\n",
       "      <td>1133.37</td>\n",
       "      <td>1205.58</td>\n",
       "      <td>1261.73</td>\n",
       "      <td>1216.36</td>\n",
       "      <td>1250.07</td>\n",
       "      <td>1294.11</td>\n",
       "      <td>1362.40</td>\n",
       "      <td>1388.73</td>\n",
       "      <td>1147.69</td>\n",
       "      <td>1186.26</td>\n",
       "      <td>1243.51</td>\n",
       "      <td>1004.65</td>\n",
       "      <td>1063.67</td>\n",
       "      <td>1142.83</td>\n",
       "      <td>1276.82</td>\n",
       "      <td>1231.36</td>\n",
       "      <td>1339.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-01 02:00:00</td>\n",
       "      <td>1511.15</td>\n",
       "      <td>30.90</td>\n",
       "      <td>139.16</td>\n",
       "      <td>1546.72</td>\n",
       "      <td>1629.32</td>\n",
       "      <td>1698.09</td>\n",
       "      <td>1852.77</td>\n",
       "      <td>1692.17</td>\n",
       "      <td>1743.35</td>\n",
       "      <td>1850.72</td>\n",
       "      <td>1320.15</td>\n",
       "      <td>1345.53</td>\n",
       "      <td>1357.86</td>\n",
       "      <td>1356.33</td>\n",
       "      <td>1400.48</td>\n",
       "      <td>1465.08</td>\n",
       "      <td>1493.41</td>\n",
       "      <td>1060.36</td>\n",
       "      <td>1070.76</td>\n",
       "      <td>1090.07</td>\n",
       "      <td>1133.37</td>\n",
       "      <td>1205.58</td>\n",
       "      <td>1226.75</td>\n",
       "      <td>1216.36</td>\n",
       "      <td>1250.07</td>\n",
       "      <td>1294.11</td>\n",
       "      <td>1362.40</td>\n",
       "      <td>1137.57</td>\n",
       "      <td>1147.69</td>\n",
       "      <td>1186.26</td>\n",
       "      <td>1008.12</td>\n",
       "      <td>1004.65</td>\n",
       "      <td>1063.67</td>\n",
       "      <td>1231.36</td>\n",
       "      <td>1186.95</td>\n",
       "      <td>1276.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               period   demand  air_temp   price    lag_1    lag_2    lag_3  \\\n",
       "0 2017-03-01 00:00:00  1852.77     34.00   46.93  1692.17  1743.35  1850.72   \n",
       "1 2017-03-01 00:30:00  1698.09     33.80   70.58  1852.77  1692.17  1743.35   \n",
       "2 2017-03-01 01:00:00  1629.32     33.60  119.52  1698.09  1852.77  1692.17   \n",
       "3 2017-03-01 01:30:00  1546.72     32.25  105.58  1629.32  1698.09  1852.77   \n",
       "4 2017-03-01 02:00:00  1511.15     30.90  139.16  1546.72  1629.32  1698.09   \n",
       "\n",
       "     lag_4    lag_5    lag_6    lag_7   lag_45   lag_46   lag_47   lag_48  \\\n",
       "0  1975.58  2098.78  2209.24  2291.59  1400.48  1465.08  1493.41  1599.68   \n",
       "1  1850.72  1975.58  2098.78  2209.24  1356.33  1400.48  1465.08  1493.41   \n",
       "2  1743.35  1850.72  1975.58  2098.78  1357.86  1356.33  1400.48  1465.08   \n",
       "3  1692.17  1743.35  1850.72  1975.58  1345.53  1357.86  1356.33  1400.48   \n",
       "4  1852.77  1692.17  1743.35  1850.72  1320.15  1345.53  1357.86  1356.33   \n",
       "\n",
       "    lag_49   lag_50   lag_51  lag_334  lag_335  lag_336  lag_337  lag_338  \\\n",
       "0  1429.60  1480.51  1540.91  1205.58  1261.73  1344.08  1175.69  1192.87   \n",
       "1  1599.68  1429.60  1480.51  1133.37  1205.58  1261.73  1344.08  1175.69   \n",
       "2  1493.41  1599.68  1429.60  1090.07  1133.37  1205.58  1261.73  1344.08   \n",
       "3  1465.08  1493.41  1599.68  1070.76  1090.07  1133.37  1205.58  1261.73   \n",
       "4  1400.48  1465.08  1493.41  1060.36  1070.76  1090.07  1133.37  1205.58   \n",
       "\n",
       "   lag_1006  lag_1007  lag_1008  lag_1009  lag_1010  lag_1679  lag_1680  \\\n",
       "0   1362.40   1388.73   1491.46   1348.77   1355.61   1311.26   1418.21   \n",
       "1   1294.11   1362.40   1388.73   1491.46   1348.77   1243.51   1311.26   \n",
       "2   1250.07   1294.11   1362.40   1388.73   1491.46   1186.26   1243.51   \n",
       "3   1216.36   1250.07   1294.11   1362.40   1388.73   1147.69   1186.26   \n",
       "4   1226.75   1216.36   1250.07   1294.11   1362.40   1137.57   1147.69   \n",
       "\n",
       "   lag_1681  lag_287  lag_288  lag_289  lag_672  lag_671  lag_673  \\\n",
       "0   1244.27  1201.42  1275.00  1100.42  1509.93  1401.17  1335.70   \n",
       "1   1418.21  1142.83  1201.42  1275.00  1401.17  1339.87  1509.93   \n",
       "2   1311.26  1063.67  1142.83  1201.42  1339.87  1276.82  1401.17   \n",
       "3   1243.51  1004.65  1063.67  1142.83  1276.82  1231.36  1339.87   \n",
       "4   1186.26  1008.12  1004.65  1063.67  1231.36  1186.95  1276.82   \n",
       "\n",
       "   dummy_Balckout  dummy_HeatWaves  dummy_Winter  dummy_Spring  dummy_Summer  \n",
       "0               0                0             0             0             0  \n",
       "1               0                0             0             0             0  \n",
       "2               0                0             0             0             0  \n",
       "3               0                0             0             0             0  \n",
       "4               0                0             0             0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df_test = pd.read_csv('../../../0. Data/data_demand_cleaned_ML181026_test.csv', sep='\\t')\n",
    "df_test['period'] = pd.to_datetime(df_test['period'], format='%d/%m/%Y %H:%M')\n",
    "df_test.sort_values(by='period', ascending=True, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to remove the 1681 rows which contain NaN values. Otherwise, we will get errors when trying to create our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.dropna(axis=0, inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a test set of approximately 20% then we need the last two months of data which are March 2017 and April 2017. This gives us a test set of approximately 18.5%. We do the same for the validation set which is January 2017 and February 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training and test sets\n",
    "# split_point = 12910\n",
    "# df_train_validate = df.iloc[0:split_point,:]\n",
    "# df_test = df.iloc[split_point:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training and validation sets\n",
    "# split_point = 10078\n",
    "# df_train = df_train_validate.iloc[0:split_point,:]\n",
    "# df_validate = df_train_validate.iloc[split_point:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle \n",
    "from sklearn.utils import shuffle\n",
    "df_train = shuffle(df_train)\n",
    "#df_validate = shuffle(df_validate)\n",
    "df_test = shuffle(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of y: (12910, 1)\n",
      "Dimensions of X: (12910, 40)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data\n",
    "X_train = df_train[[\"air_temp\", \"price\", \"lag_1\", \"lag_2\", \"lag_3\", \"lag_4\", \"lag_5\", \"lag_6\", \"lag_7\", \"lag_45\", \"lag_46\", \"lag_47\", \"lag_48\", \"lag_49\", \"lag_50\", \"lag_51\", \"lag_334\", \"lag_335\", \"lag_336\", \"lag_337\", \"lag_338\", \"lag_1006\", \"lag_1007\", \"lag_1008\", \"lag_1009\", \"lag_1010\", \"lag_1679\", \"lag_1680\", \"lag_1681\", \"lag_287\", \"lag_288\", \"lag_289\", \"lag_672\",\"lag_671\", \"lag_673\", \"dummy_Balckout\", \"dummy_HeatWaves\", \"dummy_Winter\", \"dummy_Spring\", \"dummy_Summer\"]]\n",
    "y_train = df_train[['demand']]\n",
    "\n",
    "# Print the dimensions of X and y \n",
    "print(\"Dimensions of y: {}\".format(y_train.shape))\n",
    "print(\"Dimensions of X: {}\".format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the data\n",
    "# X_validate = df_validate[[\"air_temp\", \"price\", \"lag_1\", \"lag_2\", \"lag_3\", \"lag_4\", \"lag_5\", \"lag_6\", \"lag_7\", \"lag_45\", \"lag_46\", \"lag_47\", \"lag_48\", \"lag_49\", \"lag_50\", \"lag_51\", \"lag_334\", \"lag_335\", \"lag_336\", \"lag_337\", \"lag_338\", \"lag_1006\", \"lag_1007\", \"lag_1008\", \"lag_1009\", \"lag_1010\", \"lag_1679\", \"lag_1680\", \"lag_1681\", \"lag_287\", \"lag_288\", \"lag_289\", \"dummy_Balckout\", \"dummy_HeatWaves\", \"dummy_Winter\", \"dummy_Spring\", \"dummy_Summer\"]]\n",
    "# y_validate = df_validate[['demand']]\n",
    "\n",
    "# # Print the dimensions of X and y \n",
    "# print(\"Dimensions of y: {}\".format(y_validate.shape))\n",
    "# print(\"Dimensions of X: {}\".format(X_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of y: (2909, 1)\n",
      "Dimensions of X: (2909, 40)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data\n",
    "X_test = df_test[[\"air_temp\", \"price\", \"lag_1\", \"lag_2\", \"lag_3\", \"lag_4\", \"lag_5\", \"lag_6\", \"lag_7\", \"lag_45\", \"lag_46\", \"lag_47\", \"lag_48\", \"lag_49\", \"lag_50\", \"lag_51\", \"lag_334\", \"lag_335\", \"lag_336\", \"lag_337\", \"lag_338\", \"lag_1006\", \"lag_1007\", \"lag_1008\", \"lag_1009\", \"lag_1010\", \"lag_1679\", \"lag_1680\", \"lag_1681\", \"lag_287\", \"lag_288\", \"lag_289\", \"lag_672\",\"lag_671\", \"lag_673\", \"dummy_Balckout\", \"dummy_HeatWaves\", \"dummy_Winter\", \"dummy_Spring\", \"dummy_Summer\"]]\n",
    "y_test = df_test[['demand']]\n",
    "\n",
    "# Print the dimensions of X and y \n",
    "print(\"Dimensions of y: {}\".format(y_test.shape))\n",
    "print(\"Dimensions of X: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Transformation\n",
    "Making sure we only transform the numerical features and not the two dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now create a list of numerical variables which will later be transformed\n",
    "categorical = ['dummy_Balckout', 'dummy_HeatWaves', 'dummy_Winter', 'dummy_Spring', 'dummy_Summer']\n",
    "exclude = categorical\n",
    "numerical=[x for x in list(X_train.columns) if x not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numerical and categorical subsets of the data\n",
    "X_train_numerical=X_train[numerical]\n",
    "#X_validate_numerical=X_validate[numerical]\n",
    "X_test_numerical=X_test[numerical]\n",
    "\n",
    "X_train_categorical=X_train[categorical]\n",
    "#X_validate_categorical=X_validate[categorical]\n",
    "X_test_categorical=X_test[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StandardScaler to transform numerical data\n",
    "sc = StandardScaler().fit(X_train_numerical)\n",
    "X_train_numerical_sc = sc.transform(X_train_numerical)\n",
    "#X_validate_numerical_sc = sc.transform(X_validate_numerical)\n",
    "X_test_numerical_sc = sc.transform(X_test_numerical)\n",
    "\n",
    "# Add others here later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index from the previous numerical df\n",
    "train_index = X_train_numerical.index\n",
    "#validate_index = X_validate_numerical.index\n",
    "test_index = X_test_numerical.index\n",
    "\n",
    "# Create dataframe\n",
    "X_train_numerical_sc = pd.DataFrame(X_train_numerical_sc, columns=numerical, index=train_index)\n",
    "#X_validate_numerical_sc = pd.DataFrame(X_validate_numerical_sc, columns=numerical, index=validate_index)\n",
    "X_test_numerical_sc = pd.DataFrame(X_test_numerical_sc, columns=numerical, index=test_index)\n",
    "\n",
    "# Combine the data again to form the complete data set\n",
    "X_train = pd.concat([X_train_numerical_sc, X_train_categorical], axis=1)\n",
    "#X_validate = pd.concat([X_validate_numerical_sc, X_validate_categorical], axis=1)\n",
    "X_test = pd.concat([X_test_numerical_sc, X_test_categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to arrays for modelling\n",
    "X_train = X_train.values\n",
    "#X_validate = X_validate.values\n",
    "X_test = X_test.values\n",
    "\n",
    "y_train = y_train.values\n",
    "#y_validate = y_validate.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Functions for Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv_train(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "def rmse_cv_test(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_test, y_test, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "def mae_cv_train(model):\n",
    "    mae= -cross_val_score(model, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv = 5)\n",
    "    return(mae)\n",
    "\n",
    "def mae_cv_test(model):\n",
    "    mae= -cross_val_score(model, X_test, y_test, scoring=\"neg_mean_absolute_error\", cv = 5)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create Function That Constructs A Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/\n",
    "\n",
    "https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_random_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the size of the input\n",
    "n_input = X_train.shape[1]\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network(optimizer='adam', layer1_units=15, layer2_units=15, layer3_units=15, init_mode='uniform', activation='relu', dropout_rate=0.0, weight_constraint=0):\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=layer1_units, activation=activation, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint), input_shape=(n_input,)))\n",
    "    \n",
    "    # Dropout\n",
    "    network.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=layer2_units, activation=activation, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    \n",
    "    # Dropout\n",
    "    network.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=layer3_units, activation=activation, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    \n",
    "    # Dropout\n",
    "    network.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='linear', kernel_initializer=init_mode))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss='mean_squared_error', \n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=['mean_absolute_error','mean_absolute_percentage_error']) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Wrap Function In KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasRegressor(build_fn=create_network, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter space\n",
    "epochs = [500, 600, 700, 800, 900, 1200, 1600]\n",
    "batches = [5, 10, 25, 50, 100, 200]\n",
    "optimizers = ['Adam', 'Nadam']\n",
    "init_mode = ['normal', 'glorot_normal', 'he_normal']\n",
    "layer1_units = [10,15, 20, 25, 30, 35, 40, 50]\n",
    "layer2_units = [5,10, 15, 20, 25, 30, 35, 40, 50]\n",
    "layer3_units = [5,10, 15, 20, 25, 30, 35, 40, 50]\n",
    "activation = ['relu']\n",
    "weight_constraint = [1, 2, 3, 4]\n",
    "dropout_rate = [0.2, 0.3, 0.4]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init_mode=init_mode, layer1_units=layer1_units, layer2_units=layer2_units,layer3_units=layer3_units, activation=activation, dropout_rate=dropout_rate, weight_constraint=weight_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Conduct Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "#grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "\n",
    "# Randomised grid search\n",
    "grid = RandomizedSearchCV(neural_network, hyperparameters, random_state=1, n_iter=50, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Find Best Modelâ€™s Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 50,\n",
       " 'dropout_rate': 0.2,\n",
       " 'epochs': 1200,\n",
       " 'init_mode': 'he_normal',\n",
       " 'layer1_units': 25,\n",
       " 'layer2_units': 35,\n",
       " 'layer3_units': 35,\n",
       " 'optimizer': 'Nadam',\n",
       " 'weight_constraint': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View hyperparameters of best neural network\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Display the Top 5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(grid_result.cv_results_)\n",
    "df_cv_results.sort_values(by=['rank_test_score']).head(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Validation\n",
    "I will take the 3 best models and fit them manually. Then I will run them on the validation data to get their scores. Repeat the stuff from below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the size of the input\n",
    "n_input = X_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(25, input_dim=n_input, activation='relu', kernel_initializer='he_normal', kernel_constraint=maxnorm(3)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(35, activation='relu', kernel_initializer='he_normal', kernel_constraint=maxnorm(3)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(35, activation='relu', kernel_initializer='he_normal', kernel_constraint=maxnorm(3)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='linear', kernel_initializer='he_normal')) \n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='mean_squared_error', optimizer='nadam', metrics=['mean_absolute_error','mean_absolute_percentage_error'])\n",
    "\n",
    "# Fit the model\n",
    "validation_data = (X_test, y_test)\n",
    "history1 = model1.fit(X_train, y_train, epochs=1200, batch_size=50, validation_data=validation_data)\n",
    "\n",
    "# Calculate the scores\n",
    "scores1 = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history1.history['mean_absolute_percentage_error'])\n",
    "plt.plot(history1.history['val_mean_absolute_percentage_error'])\n",
    "#plt.ylim(0, 10)\n",
    "plt.title('MAPE vs Epoch')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_absolute_percentage_error: 7.79%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model1.metrics_names[2], scores1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_absolute_error: 102.33(MW)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f(MW)\" % (model1.metrics_names[1], scores1[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the size of the input\n",
    "n_input = X_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(25, input_dim=n_input, activation='relu', kernel_initializer='he_normal'))\n",
    "model2.add(Dropout(0))\n",
    "model2.add(Dense(25, activation='relu', kernel_initializer='he_normal'))\n",
    "model2.add(Dropout(0))\n",
    "model2.add(Dense(1, activation='linear', kernel_initializer='he_normal')) \n",
    "\n",
    "# Compile the model\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error','mean_absolute_percentage_error'])\n",
    "\n",
    "# Fit the model\n",
    "validation_data = (X_validate, y_validate)\n",
    "history2 = model2.fit(X_train, y_train, epochs=700, batch_size=5, validation_data=validation_data)\n",
    "\n",
    "# Calculate the scores\n",
    "scores2 = model2.evaluate(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history2.history['mean_absolute_percentage_error'])\n",
    "plt.plot(history2.history['val_mean_absolute_percentage_error'])\n",
    "#plt.ylim(0, 10)\n",
    "plt.title('MAPE vs Epoch')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[2], scores2[2]))\n",
    "print(\"\\n%s: %.2f(MW)\" % (model2.metrics_names[1], scores2[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the size of the input\n",
    "n_input = X_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(30, input_dim=n_input, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model3.add(Dropout(0))\n",
    "model3.add(Dense(35, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model3.add(Dropout(0))\n",
    "model3.add(Dense(1, activation='linear', kernel_initializer='glorot_normal')) \n",
    "\n",
    "# Compile the model\n",
    "model3.compile(loss='mean_squared_error', optimizer='nadam', metrics=['mean_absolute_error','mean_absolute_percentage_error'])\n",
    "\n",
    "# Fit the model\n",
    "validation_data = (X_validate, y_validate)\n",
    "history3 = model3.fit(X_train, y_train, epochs=300, batch_size=25, validation_data=validation_data)\n",
    "\n",
    "# Calculate the scores\n",
    "scores3 = model3.evaluate(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history3.history['mean_absolute_percentage_error'])\n",
    "plt.plot(history3.history['val_mean_absolute_percentage_error'])\n",
    "#plt.ylim(0, 10)\n",
    "plt.title('MAPE vs Epoch')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model3.metrics_names[2], scores3[2]))\n",
    "print(\"\\n%s: %.2f(MW)\" % (model3.metrics_names[1], scores3[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
